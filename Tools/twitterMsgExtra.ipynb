{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/john210808/covasim_delta/blob/main/Tools/twitterMsgExtra.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download twitter \n",
    "from  https://www.vicinitas.io/free-tools/download-user-tweets  \n",
    "    limitation: maximun 3,200 recent tweets \n",
    "    \n",
    "Please save the file in the same fold of notebook. If run in Colab, please first upload the file, or use following download code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /opt/anaconda3/lib/python3.7/site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample (1).xlsx\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "url = 'https://github.com/john210808/covasim_delta/raw/main/Tools/sample.xlsx'\n",
    "inputName = wget.download(url)\n",
    "print(inputName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can be used to unzip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zipfileName = \"@BBCPolitics_user_tweets.xlsx.zip\"\n",
    "# with zipfile.ZipFile(zipfileName,\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "baselink = \"\"\n",
    "\n",
    "def readXlsx(xlsxName):\n",
    "    global baselink\n",
    "    baselink = openpyxl.load_workbook(xlsxName)[\"tweets\"].cell(row=2, column=1).hyperlink.target\n",
    "    baselink = baselink[:baselink.rfind('/')]\n",
    "    df = pd.read_excel(xlsxName) \n",
    "    df[\"Time\"] = pd.DatetimeIndex(pd.to_datetime(df[\"UTC\"])).tz_convert('Australia/NSW')\n",
    "    df = df[[\"Tweet Id\", \"Text\", \"Name\", \"Screen Name\", \"Time\"]]\n",
    "    df[\"Tweet Id\"] = df[\"Tweet Id\"].apply(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def saveXlsx(df, name, overwrite=False):\n",
    "    tmpfile = \"__temp__.xlsx\"\n",
    "    df[\"Time\"] = df['Time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df.to_excel(tmpfile, sheet_name='result', index=False)  \n",
    "\n",
    "    workbook = load_workbook(tmpfile)\n",
    "    worksheet = workbook.active\n",
    "\n",
    "    for row in range(2, worksheet.max_row + 1):\n",
    "        filelocation = worksheet.cell(column=1, row=row)  # this is hyperlink\n",
    "        c = worksheet.cell(column=1, row=row)\n",
    "        c.hyperlink = baselink + '/' + c.value\n",
    "\n",
    "    worksheet.column_dimensions['A'].width = 21\n",
    "    worksheet.column_dimensions['B'].width = 100\n",
    "    worksheet.column_dimensions['C'].width = 12\n",
    "    worksheet.column_dimensions['D'].width = 12\n",
    "    worksheet.column_dimensions['E'].width = 15\n",
    "    \n",
    "    \n",
    "    if name.rfind(\".xlsx\") > 0:\n",
    "        name = name[:name.rfind(\".xlsx\")]\n",
    "    \n",
    "    if os.path.isfile(name + \".xlsx\") and not overwrite:\n",
    "        files = [f for f in os.listdir(\".\") if os.path.isfile(f) and f.endswith(\".xlsx\") and f.startswith(name)]\n",
    "        name = '%s%03d' % (name, len(files)) #datetime.now().strftime(\"%m%d%H%M%S\")\n",
    "    \n",
    "    workbook.save(name + \".xlsx\")\n",
    "    os.remove(tmpfile)\n",
    "    \n",
    "def process(xlsxName, outputName, start_time, end_time, words, authors = []):\n",
    "    df = readXlsx(xlsxName)\n",
    "\n",
    "    # conditions\n",
    "    cond_time = (df['Time'] >= start_time) & (df['Time'] <= end_time)\n",
    "    df = df.loc[cond_time]\n",
    "    \n",
    "    text = df[\"Text\"].str\n",
    "    isfirst = False\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if i == 0:\n",
    "            cond_text = text.contains(words[i]) \n",
    "        else:\n",
    "            cond_text = cond_text | text.contains(words[i]) \n",
    "\n",
    "#     name = df[\"Name\"].str\n",
    "#     for i in range(len(authors)):\n",
    "#         if i == 0:\n",
    "#             cond_author = name.contains(authors[i]) \n",
    "#         else:\n",
    "#             cond_author = cond_author | name.contains(authors[i]) \n",
    "\n",
    "    df = df.loc[cond_text]\n",
    "    saveXlsx(df, \"output\", True)\n",
    "    print(\"totoal number: %d\" % df.shape[0])\n",
    "    \n",
    "    df.drop(df.index, inplace=True) # reset df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Change condition and export excels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totoal number: 18\n"
     ]
    }
   ],
   "source": [
    "start_time = pd.Timestamp(\"2021-06-10 00:00:00\", tz='Australia/NSW')\n",
    "end_time =  pd.Timestamp(\"2021-08-20 23:59:59\", tz='Australia/NSW')\n",
    "words = [\"Hi\", \"sewage\"]  # find texts that contain these words\n",
    "#authors = [\"NSW Health\"]  # author\n",
    "\n",
    "inputName = 'sample.xlsx' # the downloaded excel file\n",
    "outName = \"output.xlsx\"   # the output\n",
    "\n",
    "process(inputName, outName, start_time, end_time, words);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
